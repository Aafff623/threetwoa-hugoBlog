- 时间复杂度，空间复杂度的
	- 简单估算方式
	- 估算复杂度的常见示例


# 不变的两种底层存储方式

## 本质

> 数组结构的本质： 以数组为代表的顺序存储 和 以链表为代表的链式存储，所谓的数据数据结构均是由此衍生的变形体
> 使用： **数据结构这个东西是拿来用的，而不是拿来秀的，并不是越复杂越好，简单实用、易学易维护才是王道**。

### 数组

- 数组
	- 本质： 线性连续的内存空间
	- 静态数组
		- int arr[10]的理解
		- crud的bigo和基本逻辑代码
		- 优劣：
			- 优势： 连续内存分配，索引访问查改
			- 劣势： 一次性分配之后不能随意增减，涉及到数据迁移
				- 扩容涉及到新数组的开辟和数据的复制，时间复杂度同理
	- 动态数组
		- 底层还是静态数组，将crud封装，多了自动数组空间的扩缩容
			- 实现的关键
				- 自动扩缩容，制定扩缩容的策略
				- 索引越界的检查，
					- checkElementIndex  针对元素， index < size
					- checkPositionIndex  针对插入位置  index <= size
				- 删除元素谨防内存泄漏
					- 删除元素置为null，让java垃圾回收机制自动回收
	- 环形数组
		- 本质： 利用了求模%（余数）运算，将普通数组变成逻辑上的环形数组，可以O(1) 的时间在数组头部增删元素。
		- 它维护两个指针 `start` 和 `end`，
			- `start` 指向第一个有效元素的索引
			- `end` 指向最后一个有效元素的下一个位置索引
		- 环形数组的区间被定义为左闭右开的，即 `[start, end)` 区间，因为这样初始化 `start = end = 0` 时，区间 `[0, 0)` 中没有元素，但只要让 `end` 向右移动（扩大）一位，区间 `[0, 1)` 就包含一个元素 `0` 了
		- 环形数组也可以获取指定索引的元素（随机访问），只不过不是直接访问对应索引，而是要通过 `start` 计算出真实索引


### 链表

- 链表
	- 链表&双向链表
		- 存储的基本原理
			- 组成 ListNode ( prev, val , next )
			- 由零散的内存块串联起来的链式结构
		- 优势
			- 提高内存的利用效率
			- 需要考虑扩缩容和数据搬移的问题，理论上么有容量限制
		- 局限性
			- 访问，修改不及数组
		- 基本api
			- 单链表的头尾，中间 增删改查
			- 双链表的头尾，中间  增删改查
		- 实现关键点
			- 同时支持有头尾节点的引用
			- 虚拟头尾节点
				- 处理空指针和边界问题的情况，归类成‘插入中间“的一种情况
				- 内部实现，对外不可见
					- 例如索引的计算方式
			- 内存泄漏
				- 例如 head = head.next 
					- 即便原来的头结点next指针没有断开，但是这个对象缺少了被别人的引用，因而会被java的垃圾回收机制回收释放
				- 删除节点的时候将指针置为null（好习惯）
	- 跳表
		- 介绍： 通过一些优化方式，让链表支持快速的查找操作，主要减少在查询操作所带来的时间消耗，利用空间换取时间的来优化链表的通病
		- 原理介绍： 基本是通过 多次二分indexLevel（索引的高度是logN），以此来分区判定所查值的索引
		- 查找方便了，但是需要维护多层索引（时间↓，空间↑）
		- 场景： 查找索引对应的节点，跳表还可以运用到更通用的场景，比如说有序键值对的存储和查找

---


# 队列和栈

队列和栈
- 底层
	- 可以用数组 或者 链表 实现
- 队列queue：先进先出
	- 双端队列Deque
- 栈stack： 先进后出


# 哈希表&哈希集合

## 哈希表
- 哈希表和常说的 Map（键值映射）不是同一个东西
	- Map 接口本身只定义了键值映射的一系列操作，HashMap 这种数据结构根据自身特点实现了这些操作。还有其他数据结构也实现了这个接口，比如 TreeMap、LinkedHashMap 等等 （主要是java中的清晰接口定义）
- 底层实现 
	- 一个table数组，将key -> （hash）哈希函数 -> 数组中的索引
- 几个关键：
	- key 唯一 ， value 可重复
	- 哈希函数的作用是把任意长度的输入（key）转化成固定长度的输出（索引）增删查改的方法中都会用到哈希函数来计算索引，因而哈希表的性能关键在于哈希函数的设计
	- 哈希冲突：
		- 介绍： `hash` 函数相当于是把一个无穷大的空间映射到了一个有限的索引空间，所以必然会有不同的 `key` 映射到同一个索引上
		- 解决方法：
			- *拉链法* （纵向延伸）
				- 一个key存储了一个链表
			- 线性探查法 / 开放寻址法（横向延伸）
				- 顺位向后找坑位
		- 能够解决哈希冲突，但取而代之的是导致性能下降，前者是需要遍历链表，后者是key值需要顺着索引向后找到为止，即连续探查
	- 负载因子
		- 介绍：负载因子是一个哈希表装满的程度的度量。一般来说，负载因子越大，说明哈希表里面存储的 `key-value` 对越多，哈希冲突的概率就越大，哈希表的操作性能就越差。
		- 计算方式： size(key-value对数量) / table.length (哈希表底层数组的数量)
		- 须知：
			- 像 Java 的 HashMap，允许我们创建哈希表时自定义负载因子，不设置的话默认是 `0.75`，**当哈希表内元素达到负载因子时，哈希表会扩容**。
			- 不能依赖哈希表的遍历方式，主要是因为哈希表达到负载因子的时候会扩容，将数据搬移，hash函数依赖table.length重新计算key的哈希值，使得同一个key存储在table的索引可能发生变化，最终导致的遍历顺序不同 （扩缩容导致哈希值发生变化）
			- 避免for中边遍历边增删：遍历哈希表的 `key`，本质就是遍历哈希表底层的 `table` 数组，如果一边遍历一边增删元素，如果遍历到一半，插入/删除操作触发了扩缩容，整个 `table` 数组都变了
			- key必须是不可变的，不建议把可变类型作为 `key`
				- 带来的问题
					- 效率问题：如用ArrayList作为key时，遍历使得性能退化至N，
					- 内存泄漏：其次修改数组中的元素的时候导致返回的hashCode变化，导致变量在哈希表中查询失效，虽然arr的键值对数据依然存在，但是arr的hashCode改变了使得arr这个变量被map引用着，无法被垃圾回收
				- 解决方式：
					- 使用不可变类型作为哈希表的 `key`，比方说用 `String` 类型作为 `key`。因为 Java 中的 `String` 对象一旦创建出来，它的值就不允许被改变，你就不会遇到上面的问题。
						- `String` 类型的 `hashCode` 方法也需要遍历所有字符，但是由于它的不可变性，这个值只要算出来一次，就可以缓存下来，不用每次都重新计算，所以 [平均时间复杂度](https://labuladong.online/algo/essential-technique/complexity-analysis/) 依然是 O(1)O(1)。

哈希函数的映射： (  key.hashCode() & 0x7fffffff ) % table.length 

## 实现哈希表的难点
`hash` 函数的作用是在 O(1)O(1) 的时间把 `key` 转化成数组的索引，而 `key` 可以是任意不可变的类型。
### 拉链法实现
`table` 中每个元素都是一个链表，出现哈希冲突的话往链表里塞元素

### 线性探查法实现
涉及到多种数组操作技巧
- 需要环形数组的技巧
- 删除操作比较复杂，需要维护元素的连续性
	- 数据搬移避免空洞，**只把在 `hash(key) = 0` 出现哈希冲突的元素往前挪，其他元素要不动，这样才能保证线性探查的正确性**。
	- 占位符标记删除，**通过一个特殊值作为占位符来标记被删元素，这样就可以避免数据搬移，同时保证元素连续**。
		- 好处 不需要进行数据搬移，删除操作处理起来比较简单。
		- 缺点 
			- 不断地插入和删除元素，`table` 数组中会出现很多这样占位符，这样会增加连续元素的长度，进而降低 `get` 方法线性探查的效率
			- 不断插入和删除元素，导致 `table` 中全部都是占位符。如果你不对这种情况进行特殊处理，那么此时你调用一次 `get` 方法，由于环形数组的特性，算法就会陷入死循环。

### 拉链法 & 线性探查法的比较：
大部分编程语言标准库实现的哈希表都是用拉链法，因为它更简单不容易出错，而且正如我在 [哈希表原理](https://labuladong.online/algo/data-structure-basic/hashmap-basic/) 中提到的，拉链法可以支持无限大的负载因子，而线性探查法不行。


## 哈希表的加强


### 用链表加强哈希表：
- Python dict 的键遍历顺序就是键的插入顺序，因而的话可以记录顺序
	- **让所有键按照插入顺序排列，是因为它把标准的哈希表和链表结合起来，组成了一种新的数据结构：哈希链表**。
- Golong 遍历顺序返回的是有规律的乱序
	- **哈希集合的 API 可以直接复用哈希表的 API 来实现。操作哈希集合，其实就是操作哈希表的键**
- Java 的 `LinkedHashMap`。这种数据结构兼具了哈希表 O(1)O(1) 的增删查改效率，同时又可以像数组链表一样保持键的插入顺序
	- 把这些键值对都用类似链表节点的结构串联起来，持有一个头尾结点 `head, tail` 的引用，每次把新的键插入 table 数组时，同时把这个键插入链表的尾部。
	- 我们还是可以在 O(1)O(1) 的时间复杂度内通过键查找到对应的双链表节点，进而找到键对应的值。
	- 我们可以在 O(1)O(1) 的时间复杂度内插入新的键值对。因为哈希表本身的插入操作时间复杂度是 O(1)O(1)，且双链表头尾的插入操作时间复杂度也是 O(1)O(1)。
	- 我们可以在 O(1)O(1) 的时间复杂度内删除指定的键值对。因为哈希表本身的删除操作时间复杂度是 O(1)O(1)，**删除给定双链表节点的操作时间复杂度也是 O(1)O(1)**。
		- 之前删除索引处的节点的时候是遍历前驱节点，O（N)，而今是通过哈希映射来拿到的节点，O（1）
		- 要做到这样哈希链表的实现，只能使用双链表
	- 由于链表节点的顺序是插入顺序，那么只要从头结点开始遍历这个链表，就能按照插入顺序访问所有键

### 用数组加强双链表
- 抛出问题： 添加randomKey（） api 使得均匀随机
	- 数组的随机值正常实现是 arr[r.nextInt(arr.length)]
		- 如果其中一个元素置为null，则概率不均匀
		- 若采用 i = (i + 1) % arr.length + while 寻找非空元素一样概率分不不均匀
	- 而哈希表中返回随机Key
		- 拉链法中
			- 均匀随机到一个数组索引，又均匀随机该索引存储的链表节点，得到的这个键也不是均匀随机的
		- 用keys方法遍历table数组，，把所有的键都存储到一个数组中，然后再随机返回一个键。但这样复杂度就是 O(N)O(N) 了，还是不符合要求
	- 实现方法：
		- 可以在哈希表中建立**数组元素到数组索引的映射关系**，这样就能在 O(1)O(1) 的时间复杂度内找到数组元素对应的索引了。

## 哈希集合
- 适用场景去重
	- 不会出现重复元素，可以在 O(1)O(1) 的时间增删元素，可以在 O(1)O(1) 的时间判断一个元素是否存在
- 哈希集合的 API 
	- 可以直接复用哈希表的 API 来实现。操作哈希集合，其实就是操作哈希表的键

## 针对哈希表底层原理的模拟面试问题

### 为什么常说哈希表的增删查改的效率都是O（1）
哈希表底层就是操作一个数组，其主要的时间复杂度来自于哈希函数计算索引和哈希冲突。只要保证哈希函数的复杂度在 O(1)O(1)，且合理解决哈希冲突的问题，那么增删查改的复杂度就都是 O(1)O(1)。

### 哈希表的遍历顺序为什么会发生变化
因为哈希表在达到负载因子时会扩容，这个扩容过程会导致哈希表底层的数组容量变化，哈希函数计算出来的索引也会变化，所以哈希表的遍历顺序也会变化。

### 哈希表的增删改查的效率一定是O（1）吗
不一定，正如前面分析的，只有哈希函数的复杂度是 O(1)O(1)，且合理解决哈希冲突的问题，才能保证增删查改的复杂度是 O(1)O(1)。

哈希冲突好解决，都是有标准答案的。关键是哈希函数的计算复杂度。如果使用了错误的 `key` 类型，比如前面用 `ArrayList` 作为 `key` 的例子，那么哈希表的复杂度就会退化成 O(N)O(N)

### 为什么需要用不可变类型作为哈希表的key
因为哈希表的主要操作都依赖于哈希函数计算出来的索引，如果 `key` 的哈希值会变化，会导致键值对意外丢失，产生严重的 bug。


# 二叉树基础以及常见类型


代表了一种重要的递归的思维方式（回溯，BFS，动态规划）。核心的数据结构，许多高级数据结构基于二叉树：如多叉树、二又堆、图、字典树、并査集、线段树 等

分类
- 满二叉树
	- 左右子树齐全
	- 节点数容易计算 2^h  - 1 （h ： 深度）
- 完全二叉树
	- 上至下，左至右的紧凑排列
		- 所有的空缺出现在右下侧且连续排列
		- 父子节点之间存在明显的规律
		- 左右子树中，至少有一颗是满二叉树
- 二叉搜索树
	- 节点值 ： 左小右大  ->  适合找找节点 （左右子树二分区间递进）
- 高度平衡二叉树
	- 每个节点的左右子树高度差不超过1
	- 假设有n个节点，那么高度是 O（logN）<-> 这样的crud效率高
- 自平衡二叉树
	- 增删节点的时候对树结构进行一些调整，使得高度在O（logN）
	- 红黑树： 自平衡的二叉搜索树

实现方式：
- 一般是链式存储，配备有左右子节点的指针
- 数组存储
- 函数堆栈生成的递归树
- 哈希表结构的表示


本质的遍历方式
- 递归遍历DFS
	- 遍历本质
		- 每个节点在递归触发的时候会有三次，遍历节点的顺序**仅取决于左右子节点的递归调用顺序，与其他代码无关**。
	- 常用来穷举所有的路径
- 层序遍历BFS
	- 一层一层地遍历，不过设计算法的时候需要维护depth
	- 用来寻找最短路径 （根节点到最近叶子节点的距离）
		- dfs需要遍历完二叉树，而bfs不需要
- 其余的遍历方式都是花活
- 适用的场景
- 

DFS 算法在寻找所有路径的问题中更常用，而 BFS 算法在寻找最短路径的问题中更常用。

二叉搜索树：
- 树中的每一个节点，左节点的值都要比小于该节点的值，右节点的值大于该结点的值 
	- 可以通过bst快速找到某个节点，或是在范围内找到所有的节点
- TreeMap 底层是将键值对存储在二叉搜索树的节点里面
- TreeSet 是对TreeMap的简单封装
- api
	- put get remove
	-  containsKey key  lastKey  firstKey floorKey  ceiling selectKey
	- rank rangeKeys














